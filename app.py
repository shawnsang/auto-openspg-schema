import streamlit as st
import os
from typing import List, Dict, Any
import json
from datetime import datetime

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from src.document_processor import DocumentProcessor
from src.schema_generator import SchemaGenerator
from src.schema_manager import SchemaManager
from src.llm_client import LLMClient
from src.logger import logger

def main():
    st.set_page_config(
        page_title="OpenSPG Schema è‡ªåŠ¨ç”Ÿæˆå™¨",
        page_icon="ğŸ”—",
        layout="wide"
    )
    
    st.title("ğŸ”— OpenSPG Schema è‡ªåŠ¨ç”Ÿæˆå™¨")
    st.markdown("---")
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®")
        
        # LLM é…ç½®
        st.subheader("LLM è®¾ç½®")
        
        # LLM æä¾›å•†é€‰æ‹©
        provider = st.selectbox(
            "LLM æä¾›å•†",
            ["OpenAI", "Ollama"],
            help="é€‰æ‹©è¦ä½¿ç”¨çš„ LLM æœåŠ¡æä¾›å•†"
        )
        
        if provider == "OpenAI":
            api_key = st.text_input("OpenAI API Key", type="password")
            base_url = st.text_input(
                "Base URL (å¯é€‰)", 
                placeholder="https://api.openai.com/v1",
                help="è‡ªå®šä¹‰ OpenAI å…¼å®¹æ¥å£çš„ URL"
            )
            model_name = st.text_input(
                "æ¨¡å‹åç§°",
                value="gpt-4",
                help="è¾“å…¥æ¨¡å‹åç§°ï¼Œå¦‚ gpt-4, gpt-3.5-turbo, claude-3-sonnet ç­‰"
            )
        else:  # Ollama
            api_key = None
            base_url = st.text_input(
                "Ollama URL", 
                value="http://localhost:11434",
                help="Ollama æœåŠ¡çš„ URL åœ°å€"
            )
            model_name = st.text_input(
                "æ¨¡å‹åç§°",
                value="llama2",
                help="Ollama ä¸­çš„æ¨¡å‹åç§°ï¼Œå¦‚ llama2, mistral ç­‰"
            )
        
        # æ–‡æ¡£å¤„ç†é…ç½®
        st.subheader("æ–‡æ¡£å¤„ç†è®¾ç½®")
        chunk_size = st.slider("æ–‡æ¡£åˆ†å—å¤§å°", 500, 3000, 1500)
        chunk_overlap = st.slider("åˆ†å—é‡å å¤§å°", 50, 500, 200)
        
        # Schema é…ç½®
        st.subheader("Schema è®¾ç½®")
        namespace = st.text_input("å‘½åç©ºé—´", value="Engineering")
    
    # ä¸»ç•Œé¢
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.header("ğŸ“„ æ–‡æ¡£ä¸Šä¼ ")
        uploaded_files = st.file_uploader(
            "é€‰æ‹©æ–‡æ¡£æ–‡ä»¶",
            type=["pdf", "docx", "txt"],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            st.success(f"å·²ä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶")
            for file in uploaded_files:
                st.write(f"- {file.name} ({file.size} bytes)")
    
    with col2:
        st.header("ğŸ¯ å½“å‰ Schema")
        
        # åˆå§‹åŒ– session state
        if 'schema_manager' not in st.session_state:
            st.session_state.schema_manager = SchemaManager(namespace)
        
        if 'processing_results' not in st.session_state:
            st.session_state.processing_results = []
        
        # æ˜¾ç¤ºå½“å‰ schema ç»Ÿè®¡
        stats = st.session_state.schema_manager.get_statistics()
        col2_1, col2_2, col2_3 = st.columns(3)
        with col2_1:
            st.metric("å®ä½“ç±»å‹", stats['entity_count'])
        with col2_2:
            st.metric("å±æ€§æ€»æ•°", stats['property_count'])
        with col2_3:
            st.metric("å·²å¤„ç†æ–‡æ¡£", len(st.session_state.processing_results))
    
    # å¤„ç†æŒ‰é’®
    st.markdown("---")
    
    # æ£€æŸ¥å¿…è¦æ¡ä»¶
    can_process = uploaded_files and (provider == "Ollama" or api_key)
    
    if st.button("ğŸš€ å¼€å§‹å¤„ç†æ–‡æ¡£", type="primary", disabled=not can_process):
        if provider == "OpenAI" and not api_key:
            st.error("è¯·æä¾› OpenAI API Key")
        elif not uploaded_files:
            st.error("è¯·ä¸Šä¼ è‡³å°‘ä¸€ä¸ªæ–‡æ¡£")
        else:
            process_documents(
                uploaded_files, provider.lower(), api_key, model_name, base_url,
                chunk_size, chunk_overlap, namespace
            )
    
    # æ˜¾ç¤ºå¤„ç†ç»“æœ
    if st.session_state.processing_results:
        st.header("ğŸ“Š å¤„ç†ç»“æœ")
        
        for i, result in enumerate(st.session_state.processing_results):
            with st.expander(f"æ–‡æ¡£ {i+1}: {result['filename']} - {result['timestamp']}"):
                col_r1, col_r2, col_r3 = st.columns(3)
                
                with col_r1:
                    st.metric("æ–°å¢å®ä½“", result['stats']['new_entities'])
                with col_r2:
                    st.metric("ä¿®æ”¹å®ä½“", result['stats']['modified_entities'])
                with col_r3:
                    st.metric("å»ºè®®åˆ é™¤", len(result['stats']['suggested_deletions']))
                
                if result['stats']['suggested_deletions']:
                    st.subheader("å»ºè®®åˆ é™¤çš„å®ä½“:")
                    for deletion in result['stats']['suggested_deletions']:
                        st.warning(f"**{deletion['entity']}**: {deletion['reason']}")
    
    # Schema é¢„è§ˆå’Œä¸‹è½½
    st.markdown("---")
    st.header("ğŸ“‹ Schema é¢„è§ˆ")
    
    col_s1, col_s2 = st.columns([3, 1])
    
    with col_s1:
        schema_content = st.session_state.schema_manager.generate_schema_string()
        st.code(schema_content, language="text")
    
    with col_s2:
        st.subheader("æ“ä½œ")
        
        # å¤åˆ¶æŒ‰é’®
        if st.button("ğŸ“‹ å¤åˆ¶ Schema"):
            st.code(schema_content)
            st.success("Schema å·²æ˜¾ç¤ºï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶")
        
        # ä¸‹è½½æŒ‰é’®
        st.download_button(
            label="ğŸ’¾ ä¸‹è½½ Schema",
            data=schema_content,
            file_name=f"{namespace}_schema_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            mime="text/plain"
        )
        
        # æ¸…ç©ºæŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…ç©º Schema", type="secondary"):
            st.session_state.schema_manager = SchemaManager(namespace)
            st.session_state.processing_results = []
            st.rerun()

def process_documents(uploaded_files, provider, api_key, model_name, base_url, chunk_size, chunk_overlap, namespace):
    """å¤„ç†ä¸Šä¼ çš„æ–‡æ¡£"""
    logger.info(f"å¼€å§‹å¤„ç†æ–‡æ¡£æ‰¹æ¬¡ï¼Œå…± {len(uploaded_files)} ä¸ªæ–‡ä»¶")
    logger.info(f"é…ç½®å‚æ•° - æä¾›å•†: {provider}, æ¨¡å‹: {model_name}, åˆ†å—å¤§å°: {chunk_size}, é‡å : {chunk_overlap}")
    
    # åˆå§‹åŒ–ç»„ä»¶
    try:
        logger.debug("åˆå§‹åŒ– LLM å®¢æˆ·ç«¯")
        llm_client = LLMClient(
            provider=provider,
            api_key=api_key,
            model_name=model_name,
            base_url=base_url if base_url else None
        )
        
        # æµ‹è¯•è¿æ¥
        logger.debug(f"æµ‹è¯• {provider} è¿æ¥")
        if not llm_client.test_connection():
            error_msg = f"æ— æ³•è¿æ¥åˆ° {provider} æœåŠ¡ï¼Œè¯·æ£€æŸ¥é…ç½®"
            logger.error(error_msg)
            st.error(error_msg)
            return
        
        success_msg = f"âœ… æˆåŠŸè¿æ¥åˆ° {provider} ({model_name})"
        logger.success(success_msg)
        st.success(success_msg)
        
    except Exception as e:
        error_msg = f"LLM å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        st.error(error_msg)
        return
    
    logger.debug("åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨å’ŒSchemaç”Ÿæˆå™¨")
    doc_processor = DocumentProcessor(chunk_size, chunk_overlap)
    schema_generator = SchemaGenerator(llm_client)
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, uploaded_file in enumerate(uploaded_files):
        file_progress = (i + 1) / len(uploaded_files)
        logger.info(f"å¤„ç†æ–‡ä»¶ {i+1}/{len(uploaded_files)}: {uploaded_file.name} ({uploaded_file.size} å­—èŠ‚)")
        status_text.text(f"æ­£åœ¨å¤„ç†: {uploaded_file.name}")
        
        try:
            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            temp_path = f"temp_{uploaded_file.name}"
            logger.debug(f"ä¿å­˜ä¸´æ—¶æ–‡ä»¶: {temp_path}")
            with open(temp_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # å¤„ç†æ–‡æ¡£
            logger.info(f"å¼€å§‹å¤„ç†æ–‡æ¡£: {uploaded_file.name}")
            chunks = doc_processor.process_document(temp_path)
            logger.success(f"æ–‡æ¡£å¤„ç†å®Œæˆï¼Œç”Ÿæˆ {len(chunks)} ä¸ªåˆ†å—")
            
            # ç”Ÿæˆ schema
            logger.info(f"å¼€å§‹ä» {len(chunks)} ä¸ªåˆ†å—ä¸­æå–å®ä½“")
            new_entities = 0
            modified_entities = 0
            suggested_deletions = []
            
            for chunk_idx, chunk in enumerate(chunks):
                logger.debug(f"å¤„ç†åˆ†å— {chunk_idx + 1}/{len(chunks)} ({len(chunk)} å­—ç¬¦)")
                entities = schema_generator.extract_entities_from_chunk(chunk)
                logger.debug(f"ä»åˆ†å— {chunk_idx + 1} æå–åˆ° {len(entities)} ä¸ªå®ä½“")
                
                for entity in entities:
                    logger.debug(f"å¤„ç†å®ä½“: {entity['name']}")
                    result = st.session_state.schema_manager.add_or_update_entity(
                        entity['name'], entity['description'], entity.get('properties', {})
                    )
                    
                    if result['action'] == 'created':
                        new_entities += 1
                        logger.info(f"åˆ›å»ºæ–°å®ä½“: {entity['name']}")
                    elif result['action'] == 'updated':
                        modified_entities += 1
                        logger.info(f"æ›´æ–°å®ä½“: {entity['name']}")
                    else:
                        logger.debug(f"å®ä½“æ— å˜åŒ–: {entity['name']}")
                
                # æ›´æ–°è¿›åº¦
                chunk_progress = (chunk_idx + 1) / len(chunks)
                overall_progress = (i + chunk_progress) / len(uploaded_files)
                progress_bar.progress(overall_progress)
            
            # æ£€æŸ¥å»ºè®®åˆ é™¤çš„å®ä½“
            logger.debug("æ£€æŸ¥å»ºè®®åˆ é™¤çš„å®ä½“")
            suggested_deletions = schema_generator.suggest_entity_deletions(
                st.session_state.schema_manager.get_all_entities(),
                chunks
            )
            logger.info(f"å»ºè®®åˆ é™¤ {len(suggested_deletions)} ä¸ªå®ä½“")
            
            # è®°å½•å¤„ç†ç»“æœ
            result = {
                'filename': uploaded_file.name,
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'stats': {
                    'new_entities': new_entities,
                    'modified_entities': modified_entities,
                    'suggested_deletions': suggested_deletions
                }
            }
            
            st.session_state.processing_results.append(result)
            logger.success(f"æ–‡ä»¶ {uploaded_file.name} å¤„ç†å®Œæˆ - æ–°å¢: {new_entities}, ä¿®æ”¹: {modified_entities}, å»ºè®®åˆ é™¤: {len(suggested_deletions)}")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            logger.debug(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_path}")
            os.remove(temp_path)
            
        except Exception as e:
            error_msg = f"å¤„ç†æ–‡æ¡£ {uploaded_file.name} æ—¶å‡ºé”™: {str(e)}"
            logger.error(error_msg, exc_info=True)
            st.error(error_msg)
            
            # æ¸…ç†å¯èƒ½å­˜åœ¨çš„ä¸´æ—¶æ–‡ä»¶
            temp_path = f"temp_{uploaded_file.name}"
            if os.path.exists(temp_path):
                logger.debug(f"æ¸…ç†é”™è¯¯å¤„ç†ä¸­çš„ä¸´æ—¶æ–‡ä»¶: {temp_path}")
                os.remove(temp_path)
        
        # æ›´æ–°è¿›åº¦
        progress_bar.progress((i + 1) / len(uploaded_files))
    
    # å¤„ç†å®Œæˆæ€»ç»“
    total_files = len(uploaded_files)
    successful_files = len([r for r in st.session_state.processing_results if 'stats' in r])
    failed_files = total_files - successful_files
    
    logger.success(f"æ–‡æ¡£æ‰¹æ¬¡å¤„ç†å®Œæˆ - æ€»è®¡: {total_files}, æˆåŠŸ: {successful_files}, å¤±è´¥: {failed_files}")
    
    if st.session_state.processing_results:
        total_new = sum(r.get('stats', {}).get('new_entities', 0) for r in st.session_state.processing_results)
        total_modified = sum(r.get('stats', {}).get('modified_entities', 0) for r in st.session_state.processing_results)
        logger.info(f"å®ä½“ç»Ÿè®¡ - æ–°å¢: {total_new}, ä¿®æ”¹: {total_modified}")
    
    progress_bar.progress(1.0)
    status_text.text("å¤„ç†å®Œæˆï¼")
    
    status_text.text("å¤„ç†å®Œæˆ!")
    st.success(f"æˆåŠŸå¤„ç† {len(uploaded_files)} ä¸ªæ–‡æ¡£")
    st.rerun()

if __name__ == "__main__":
    main()